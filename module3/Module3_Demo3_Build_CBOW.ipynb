{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module3_Demo3_Build_CBOW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMZMnLfm5uLWZ4hcIV5L6a8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/axel-sirota/implement-nlp-word-embedding/blob/main/module3/Module3_Demo3_Build_CBOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFQM_HAJgHEz",
        "outputId": "e37df5b6-7764-4eba-af85-49c04625c5f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import AG_NEWS\n",
        "import warnings\n",
        "import os\n",
        "from textblob import TextBlob, Word\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "warnings.filterwarnings('ignore')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile get_data.sh\n",
        "if [ ! -f yelp.csv ]; then\n",
        "  wget https://raw.githubusercontent.com/axel-sirota/implement-nlp-word-embedding/main/module3/data/yelp.csv\n",
        "fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hP5znc6NBCg",
        "outputId": "8b72ad43-f8bd-47c9-f76f-959216b68122"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting get_data.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash get_data.sh\n"
      ],
      "metadata": {
        "id": "7Bh1RqQUPWeo"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = './yelp.csv'\n",
        "yelp = pd.read_csv(path)\n",
        "text_df = yelp.text"
      ],
      "metadata": {
        "id": "7jcOGQHDPYP6"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 300\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 150\n",
        "CORPUS_SIZE = 1000\n",
        "train_size = 25000"
      ],
      "metadata": {
        "id": "s_1umLOsgk5R"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(data_iter, tokenizer):\n",
        "    \"\"\"Builds vocabulary from iterator\"\"\"\n",
        "    vocab = build_vocab_from_iterator(\n",
        "        yield_tokens(data_iter, tokenizer),\n",
        "        specials=[\"<unk>\"],\n",
        "        min_freq=10,\n",
        "    )\n",
        "    vocab.set_default_index(vocab[\"<unk>\"])\n",
        "    return vocab\n",
        "\n",
        "def yield_tokens(data_iter, tokenizer):\n",
        "    for text in data_iter:\n",
        "        yield tokenizer(text)\n"
      ],
      "metadata": {
        "id": "LNIYzlnzhZIC"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_sampled = text_df.sample(CORPUS_SIZE).values"
      ],
      "metadata": {
        "id": "ucls-7mkNQHa"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = lambda x: TextBlob(x).words\n",
        "vocab = build_vocab(text_sampled, tokenizer)\n",
        "print(f'Vocab size is {len(vocab)}')"
      ],
      "metadata": {
        "id": "0d4exCm_hyPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d080571c-d942-4c31-a6a5-144ead335328"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size is 1396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdMAq5FMjVDt",
        "outputId": "271f8ceb-7bf5-4849-da1f-d7a9d0b00b07"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Vocab()"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab(tokenizer(\"This is a fantastic ice cream\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xau74OLTjz5z",
        "outputId": "b0cf01df-e982-4e39-fb74-9374cbaf3eea"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[73, 8, 4, 403, 451, 356]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(text_sampled))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "HK_AkCK5mSwT",
        "outputId": "27d249e9-b764-46a6-972a-b62f85ebf3d9"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Absolutely unbelievable!!! This is so worth the drive from Scottsdale to Tempe! But get there early as they close early and run out of food! It's so delicious my mouth is watering just thinking about it. I love French pastries, crepes and desserts! The macaroons melt in your mouth. I will be returning soon!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "word_to_ix = {}\n",
        "for sentence in text_sampled:\n",
        "  for word in tokenizer(sentence):\n",
        "    word_to_ix[word] = vocab([word])[0]"
      ],
      "metadata": {
        "id": "6y7KGL1fiMDc"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ix_to_word = {ix:word for word, ix in word_to_ix.items()}"
      ],
      "metadata": {
        "id": "NPwMGoeyjEy6"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for sentence in text_sampled:\n",
        "  tokenized_sentence = tokenizer(sentence)\n",
        "  for i in range(2, len(tokenized_sentence) - 2):\n",
        "    context = [tokenized_sentence[i - 2], tokenized_sentence[i - 1],\n",
        "               tokenized_sentence[i + 1], tokenized_sentence[i + 2]]\n",
        "    target = tokenized_sentence[i]\n",
        "    data.append((context, target))"
      ],
      "metadata": {
        "id": "BCcPLFM0kqc_"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Lenght of input (sampled) text set is {len(data)}, reducing it to {train_size}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM0Znu5VP5D2",
        "outputId": "4a46b18c-0cb1-4fd7-dad4-c09ac62eb318"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lenght of input (sampled) text set is 135377, reducing it to 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[:train_size]"
      ],
      "metadata": {
        "id": "4wkpTaHSQIcw"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_context_vector(context, word_to_ix):\n",
        "    idxs = [word_to_ix[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long).to(device)"
      ],
      "metadata": {
        "id": "Mb0CbAZ4qihA"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOW(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(CBOW, self).__init__()\n",
        "\n",
        "        #out: 1 x emdedding_dim\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(embedding_dim, vocab_size)\n",
        "        self.activation_function2 = nn.LogSoftmax(dim = -1)\n",
        "        \n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = sum(self.embeddings(inputs)).view(1,-1)\n",
        "        out = self.linear1(embeds)\n",
        "        out = self.activation_function2(out)\n",
        "        return out\n",
        "\n",
        "    def get_word_emdedding(self, word):\n",
        "        word = torch.tensor([word_to_ix[word]])\n",
        "        return self.embeddings(word).view(1,-1)"
      ],
      "metadata": {
        "id": "Ils21-oJqizc"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CBOW(vocab_size, EMBEDDING_DIM).to(device)"
      ],
      "metadata": {
        "id": "r9z1qVbYre9O"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(y_pred, y):\n",
        "  return nn.functional.nll_loss(y_pred, y)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters())"
      ],
      "metadata": {
        "id": "iBTpSE2PrhYL"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_pd = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "Y2lNhbSSv73x"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "pNKBxIZuwPHa",
        "outputId": "ac6b86cb-3ec4-42b5-c0c0-6dec9ee04534"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        0      1\n",
              "0      [Absolutely, unbelievable, is, so]   This\n",
              "1         [unbelievable, This, so, worth]     is\n",
              "2                  [This, is, worth, the]     so\n",
              "3                    [is, so, the, drive]  worth\n",
              "4                [so, worth, drive, from]    the\n",
              "...                                   ...    ...\n",
              "24995               [my, fix, fry, bread]     of\n",
              "24996             [fix, of, bread, There]    fry\n",
              "24997             [of, fry, There, needs]  bread\n",
              "24998             [fry, bread, needs, to]  There\n",
              "24999              [bread, There, to, be]  needs\n",
              "\n",
              "[25000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18d352cd-5fe8-44da-9f53-87b6c54a4b1e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Absolutely, unbelievable, is, so]</td>\n",
              "      <td>This</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[unbelievable, This, so, worth]</td>\n",
              "      <td>is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[This, is, worth, the]</td>\n",
              "      <td>so</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[is, so, the, drive]</td>\n",
              "      <td>worth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[so, worth, drive, from]</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>[my, fix, fry, bread]</td>\n",
              "      <td>of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>[fix, of, bread, There]</td>\n",
              "      <td>fry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>[of, fry, There, needs]</td>\n",
              "      <td>bread</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>[fry, bread, needs, to]</td>\n",
              "      <td>There</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>[bread, There, to, be]</td>\n",
              "      <td>needs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18d352cd-5fe8-44da-9f53-87b6c54a4b1e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18d352cd-5fe8-44da-9f53-87b6c54a4b1e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18d352cd-5fe8-44da-9f53-87b6c54a4b1e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  total_loss = 0\n",
        "  ix = 0\n",
        "  for context, target in data:\n",
        "      context_vector = make_context_vector(context, word_to_ix)\n",
        "      log_probs = model(context_vector)\n",
        "      total_loss += loss_function(log_probs, torch.tensor([word_to_ix[target]]).to(device))\n",
        "      if ix > BATCH_SIZE:\n",
        "        print(f\"-\"*59)\n",
        "        print(f\"Epoch: {epoch}, Batch: {ix+1}, Loss: {total_loss}\")\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        total_loss = 0"
      ],
      "metadata": {
        "id": "mj2XomjrtOlH"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = ['People','create','to', 'direct']\n",
        "context_vector = make_context_vector(context, word_to_ix)\n",
        "a = model(context_vector)\n",
        "\n",
        "#Print result\n",
        "print(f'Context: {context}\\n')\n",
        "print(f'Prediction: {ix_to_word[torch.argmax(a[0]).item()]}')"
      ],
      "metadata": {
        "id": "baEKAnFTt6ZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "254cd95c-edd6-4865-8db3-94157eb0cec1"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: ['People', 'create', 'to', 'direct']\n",
            "\n",
            "Prediction: delicious\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding from first model layer\n",
        "embeddings = list(model.parameters())[0]\n",
        "embeddings = embeddings.cpu().detach().numpy()\n",
        "\n",
        "# normalization\n",
        "norms = (embeddings ** 2).sum(axis=1) ** (1 / 2)\n",
        "norms = np.reshape(norms, (len(norms), 1))\n",
        "embeddings_norm = embeddings / norms\n",
        "embeddings_norm.shape"
      ],
      "metadata": {
        "id": "V3N0NXnSuzVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "101a9378-eb91-470b-a4f2-c097338d1a83"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1396, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_similar(word, topN=10):\n",
        "    word_vec = model.to(\"cpu\").get_word_emdedding(word).detach().numpy()[0]\n",
        "    word_vec = np.reshape(word_vec, (len(word_vec), 1))\n",
        "    dists = np.matmul(embeddings_norm, word_vec).flatten()\n",
        "    topN_ids = np.argsort(-dists)[1 : topN + 1]\n",
        "    topN_dict = {}\n",
        "    for sim_word_id in topN_ids:\n",
        "        sim_word = ix_to_word[sim_word_id]\n",
        "        topN_dict[sim_word] = dists[sim_word_id]\n",
        "    return topN_dict\n",
        "\n",
        "model.eval()\n",
        "for word, sim in get_top_similar(\"excellent\").items():\n",
        "    print(\"{}: {:.3f}\".format(word, sim))\n",
        "\n"
      ],
      "metadata": {
        "id": "b51uwCryuZnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3af0b7f0-d034-4fe4-9064-303576f5e778"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stores: 3.091\n",
            "children: 2.749\n",
            "love: 2.705\n",
            "hear: 2.616\n",
            "story: 2.612\n",
            "hummus: 2.586\n",
            "terrible: 2.489\n",
            "due: 2.488\n",
            "served: 2.473\n",
            "same: 2.471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZouAmamvTE8W"
      },
      "execution_count": 90,
      "outputs": []
    }
  ]
}