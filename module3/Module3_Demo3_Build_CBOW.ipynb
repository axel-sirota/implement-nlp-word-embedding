{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module3_Demo3_Build_CBOW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN7Y2ps96aNHje4wgFbbDKL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/axel-sirota/implement-nlp-word-embedding/blob/main/module3/Module3_Demo3_Build_CBOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK1bATCjslcP",
        "outputId": "e67a5a69-9818-4519-b858-5f46c9c17d85"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat May 28 17:32:24 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    38W / 300W |   1445MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFQM_HAJgHEz",
        "outputId": "43763158-ba43-4007-90bf-24ab0ae5bcae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import AG_NEWS\n",
        "import warnings\n",
        "import os\n",
        "from textblob import TextBlob, Word\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "warnings.filterwarnings('ignore')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile get_data.sh\n",
        "if [ ! -f yelp.csv ]; then\n",
        "  wget https://raw.githubusercontent.com/axel-sirota/implement-nlp-word-embedding/main/module3/data/yelp.csv\n",
        "fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hP5znc6NBCg",
        "outputId": "62dc36e9-19b2-4373-91a0-a2877dda174e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting get_data.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash get_data.sh\n"
      ],
      "metadata": {
        "id": "7Bh1RqQUPWeo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = './yelp.csv'\n",
        "yelp = pd.read_csv(path)\n",
        "text_df = yelp.text"
      ],
      "metadata": {
        "id": "7jcOGQHDPYP6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 50\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 2500\n",
        "CORPUS_SIZE = 2000\n",
        "train_size = 50000"
      ],
      "metadata": {
        "id": "s_1umLOsgk5R"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xbhIGLlHskQN"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(data_iter, tokenizer):\n",
        "    \"\"\"Builds vocabulary from iterator\"\"\"\n",
        "    vocab = build_vocab_from_iterator(\n",
        "        yield_tokens(data_iter, tokenizer),\n",
        "        specials=[\"<unk>\"],\n",
        "        min_freq=10,\n",
        "    )\n",
        "    vocab.set_default_index(vocab[\"<unk>\"])\n",
        "    return vocab\n",
        "\n",
        "def yield_tokens(data_iter, tokenizer):\n",
        "    for text in data_iter:\n",
        "        yield tokenizer(text)\n"
      ],
      "metadata": {
        "id": "LNIYzlnzhZIC"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_sampled = text_df.sample(CORPUS_SIZE).values"
      ],
      "metadata": {
        "id": "ucls-7mkNQHa"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = lambda x: TextBlob(x).words\n",
        "vocab = build_vocab(text_sampled, tokenizer)\n",
        "print(f'Vocab size is {len(vocab)}')"
      ],
      "metadata": {
        "id": "0d4exCm_hyPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb175ddd-0135-487f-cff7-ba98f7c23f10"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size is 2295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdMAq5FMjVDt",
        "outputId": "074206fb-5ca0-4530-e7b5-a62226f03b72"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Vocab()"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab(tokenizer(\"This is a fantastic ice cream\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xau74OLTjz5z",
        "outputId": "7a9e0766-b15c-4028-a29b-a79cb9d6cd48"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[79, 8, 4, 384, 339, 264]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(text_sampled))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "HK_AkCK5mSwT",
        "outputId": "ab5cf5be-3e96-47c4-9aa9-e077c53a67cc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Zipps has good bar food, but the service is usually horrible. The waitresses rarely come to your table. BUT, what really rubs me the wrong way is this....\\nOn multiple occasions, when I pay the bill, the waiter doesn't bring me back the correct change. Even if my change is 1 cent, I'm entitled to receive my money back. \\nI'm sorry, but not giving me back my  change because you deem it insignificant doesn't float well with me. They do have great food though.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "word_to_ix = {}\n",
        "for sentence in text_sampled:\n",
        "  for word in tokenizer(sentence):\n",
        "    word_to_ix[word] = vocab([word])[0]"
      ],
      "metadata": {
        "id": "6y7KGL1fiMDc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ix_to_word = {ix:word for word, ix in word_to_ix.items()}"
      ],
      "metadata": {
        "id": "NPwMGoeyjEy6"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for sentence in text_sampled:\n",
        "  tokenized_sentence = tokenizer(sentence)\n",
        "  for i in range(2, len(tokenized_sentence) - 2):\n",
        "    context = [tokenized_sentence[i - 2], tokenized_sentence[i - 1],\n",
        "               tokenized_sentence[i + 1], tokenized_sentence[i + 2]]\n",
        "    target = tokenized_sentence[i]\n",
        "    data.append((context, target))"
      ],
      "metadata": {
        "id": "BCcPLFM0kqc_"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Lenght of input (sampled) text set is {len(data)}, reducing it to {train_size}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM0Znu5VP5D2",
        "outputId": "74c8420c-0e89-4289-8964-b2b1b3303492"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lenght of input (sampled) text set is 261562, reducing it to 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[:train_size]"
      ],
      "metadata": {
        "id": "4wkpTaHSQIcw"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_context_vector(context, word_to_ix):\n",
        "    idxs = [word_to_ix[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long).to(device)"
      ],
      "metadata": {
        "id": "Mb0CbAZ4qihA"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOW(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(CBOW, self).__init__()\n",
        "\n",
        "        #out: 1 x emdedding_dim\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(embedding_dim, vocab_size)\n",
        "        self.activation_function2 = nn.LogSoftmax(dim = -1)\n",
        "        \n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = sum(self.embeddings(inputs)).view(1,-1)\n",
        "        out = self.linear1(embeds)\n",
        "        out = self.activation_function2(out)\n",
        "        return out\n",
        "\n",
        "    def get_word_emdedding(self, word):\n",
        "        word = torch.tensor([word_to_ix[word]])\n",
        "        return self.embeddings(word).view(1,-1)"
      ],
      "metadata": {
        "id": "Ils21-oJqizc"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CBOW(vocab_size, EMBEDDING_DIM).to(device)"
      ],
      "metadata": {
        "id": "r9z1qVbYre9O"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(y_pred, y):\n",
        "  return nn.functional.nll_loss(y_pred, y)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters())"
      ],
      "metadata": {
        "id": "iBTpSE2PrhYL"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  total_loss = 0\n",
        "  n_rows = 1\n",
        "  batches = 1\n",
        "  for context, target in data:\n",
        "      context_vector = make_context_vector(context, word_to_ix)\n",
        "      log_probs = model(context_vector)\n",
        "      total_loss += loss_function(log_probs, torch.tensor([word_to_ix[target]]).to(device))\n",
        "      if n_rows > BATCH_SIZE:\n",
        "        print(f\"-\"*59)\n",
        "        print(f\"Epoch: {epoch}, Batch: {batches}, Loss: {total_loss}\")\n",
        "        batches += 1\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        total_loss = 0\n",
        "        n_rows = 0\n",
        "      n_rows += 1"
      ],
      "metadata": {
        "id": "mj2XomjrtOlH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b01fa982-9c50-4df9-8c66-bc1147b4e17f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 1, Loss: 21423.90625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 2, Loss: 21304.876953125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 3, Loss: 21323.130859375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 4, Loss: 21183.296875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 5, Loss: 21090.353515625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 6, Loss: 21037.068359375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 7, Loss: 20893.548828125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 8, Loss: 20765.15625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 9, Loss: 20837.5234375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 10, Loss: 20748.6484375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 11, Loss: 20630.279296875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 12, Loss: 20454.294921875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 13, Loss: 20340.765625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 14, Loss: 20410.9921875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 15, Loss: 20321.45703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 16, Loss: 20274.927734375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 17, Loss: 20170.09375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 18, Loss: 19929.51171875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 19, Loss: 19958.58984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 1, Loss: 19751.5390625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 2, Loss: 19657.62109375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 3, Loss: 19722.662109375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 4, Loss: 19557.447265625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 5, Loss: 19505.2890625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 6, Loss: 19565.421875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 7, Loss: 19540.080078125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 8, Loss: 19365.5625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 9, Loss: 19506.603515625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 10, Loss: 19201.607421875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 11, Loss: 19116.87109375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 12, Loss: 19120.28125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 13, Loss: 19060.64453125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 14, Loss: 19101.150390625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 15, Loss: 18969.0546875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 16, Loss: 18953.619140625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 17, Loss: 18924.640625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 18, Loss: 18633.146484375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 19, Loss: 18654.548828125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 1, Loss: 18534.6484375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 2, Loss: 18409.708984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 3, Loss: 18475.021484375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 4, Loss: 18291.357421875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 5, Loss: 18254.16796875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 6, Loss: 18356.712890625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 7, Loss: 18436.978515625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 8, Loss: 18192.3984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 9, Loss: 18397.544921875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 10, Loss: 17913.0\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 11, Loss: 17862.076171875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 12, Loss: 17985.6484375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 13, Loss: 17965.806640625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 14, Loss: 17986.408203125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 15, Loss: 17824.958984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 16, Loss: 17823.53125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 17, Loss: 17853.935546875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 18, Loss: 17526.541015625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 19, Loss: 17532.34765625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 1, Loss: 17485.333984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 2, Loss: 17348.2734375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 3, Loss: 17413.013671875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 4, Loss: 17240.021484375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 5, Loss: 17214.55859375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 6, Loss: 17319.32421875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 7, Loss: 17496.681640625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 8, Loss: 17183.765625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 9, Loss: 17457.052734375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 10, Loss: 16851.41015625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 11, Loss: 16828.34375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 12, Loss: 17026.43359375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 13, Loss: 17036.224609375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 14, Loss: 17054.205078125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 15, Loss: 16883.4375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 16, Loss: 16881.197265625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 17, Loss: 16965.36328125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 18, Loss: 16624.33203125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 19, Loss: 16610.78515625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 1, Loss: 16606.3984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 2, Loss: 16483.970703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 3, Loss: 16552.734375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 4, Loss: 16416.224609375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 5, Loss: 16410.1484375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 6, Loss: 16475.88671875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 7, Loss: 16725.5078125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 8, Loss: 16364.5087890625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 9, Loss: 16699.345703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 10, Loss: 16039.875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 11, Loss: 16031.6376953125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 12, Loss: 16261.1875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 13, Loss: 16285.033203125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 14, Loss: 16313.94921875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 15, Loss: 16146.357421875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 16, Loss: 16140.9697265625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 17, Loss: 16264.0400390625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 18, Loss: 15925.4296875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 19, Loss: 15898.712890625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 1, Loss: 15914.11328125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 2, Loss: 15810.9521484375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 3, Loss: 15882.1650390625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 4, Loss: 15790.763671875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 5, Loss: 15804.0595703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 6, Loss: 15810.3046875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 7, Loss: 16107.28125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 8, Loss: 15720.26953125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 9, Loss: 16103.8125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 10, Loss: 15431.6611328125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 11, Loss: 15433.2626953125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 12, Loss: 15661.0166015625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 13, Loss: 15676.001953125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 14, Loss: 15732.88671875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 15, Loss: 15565.6845703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 16, Loss: 15569.0048828125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 17, Loss: 15706.2578125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 18, Loss: 15378.4619140625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 19, Loss: 15344.140625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 1, Loss: 15376.21875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 2, Loss: 15284.5078125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 3, Loss: 15350.6748046875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 4, Loss: 15299.1298828125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 5, Loss: 15326.708984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 6, Loss: 15279.552734375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 7, Loss: 15612.5419921875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 8, Loss: 15211.6689453125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 9, Loss: 15628.146484375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 10, Loss: 14959.1337890625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 11, Loss: 14976.125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 12, Loss: 15185.4892578125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 13, Loss: 15181.408203125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 14, Loss: 15270.03515625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 15, Loss: 15105.462890625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 16, Loss: 15122.408203125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 17, Loss: 15254.5048828125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 18, Loss: 14939.9072265625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 19, Loss: 14897.42578125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 1, Loss: 14945.5869140625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 2, Loss: 14861.65234375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 3, Loss: 14920.2216796875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 4, Loss: 14896.75390625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 5, Loss: 14938.158203125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 6, Loss: 14847.2529296875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 7, Loss: 15210.283203125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 8, Loss: 14799.162109375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 9, Loss: 15230.0\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 10, Loss: 14567.88671875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 11, Loss: 14603.8544921875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 12, Loss: 14791.7578125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 13, Loss: 14771.794921875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 14, Loss: 14883.04296875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 15, Loss: 14724.302734375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 16, Loss: 14756.7939453125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 17, Loss: 14874.69140625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 18, Loss: 14573.0048828125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 19, Loss: 14524.443359375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 1, Loss: 14587.2705078125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 2, Loss: 14508.931640625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 3, Loss: 14559.4599609375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 4, Loss: 14553.583984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 5, Loss: 14609.59765625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 6, Loss: 14487.2685546875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 7, Loss: 14871.8515625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 8, Loss: 14458.34375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 9, Loss: 14891.220703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 10, Loss: 14238.552734375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 11, Loss: 14291.0087890625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 12, Loss: 14460.6220703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 13, Loss: 14428.7333984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 14, Loss: 14557.1796875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 15, Loss: 14399.6884765625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 16, Loss: 14450.6875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 17, Loss: 14555.3486328125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 18, Loss: 14265.474609375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 19, Loss: 14212.75390625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 1, Loss: 14287.7666015625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 2, Loss: 14212.5009765625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 3, Loss: 14255.4345703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 4, Loss: 14259.5302734375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 5, Loss: 14328.638671875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 6, Loss: 14184.0595703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 7, Loss: 14582.5166015625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 8, Loss: 14172.9638671875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 9, Loss: 14600.7392578125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 10, Loss: 13960.2470703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 11, Loss: 14025.439453125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 12, Loss: 14179.083984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 13, Loss: 14138.2255859375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 14, Loss: 14280.017578125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 15, Loss: 14120.6943359375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 16, Loss: 14190.5400390625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 17, Loss: 14283.3486328125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 18, Loss: 14004.3505859375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 19, Loss: 13948.197265625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = ['People','create','to', 'direct']\n",
        "context_vector = make_context_vector(context, word_to_ix)\n",
        "a = model(context_vector)\n",
        "\n",
        "#Print result\n",
        "print(f'Context: {context}\\n')\n",
        "print(f'Prediction: {ix_to_word[torch.argmax(a[0]).item()]}')"
      ],
      "metadata": {
        "id": "baEKAnFTt6ZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c8044f2-876c-435c-9bcb-633b6cdec22b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: ['People', 'create', 'to', 'direct']\n",
            "\n",
            "Prediction: the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding from first model layer\n",
        "embeddings = list(model.parameters())[0]\n",
        "embeddings = embeddings.cpu().detach().numpy()\n",
        "\n",
        "# normalization\n",
        "norms = (embeddings ** 2).sum(axis=1) ** (1 / 2)\n",
        "norms = np.reshape(norms, (len(norms), 1))\n",
        "embeddings_norm = embeddings / norms\n",
        "embeddings_norm.shape"
      ],
      "metadata": {
        "id": "V3N0NXnSuzVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c230393-320f-41f8-ea9a-a451fc9b79fc"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2295, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_similar(word, topN=10):\n",
        "    word_vec = model.to(\"cpu\").get_word_emdedding(word).detach().numpy()[0]\n",
        "    word_vec = np.reshape(word_vec, (len(word_vec), 1))\n",
        "    dists = np.matmul(embeddings_norm, word_vec).flatten()\n",
        "    topN_ids = np.argsort(-dists)[1 : topN + 1]\n",
        "    topN_dict = {}\n",
        "    for sim_word_id in topN_ids:\n",
        "        sim_word = ix_to_word[sim_word_id]\n",
        "        topN_dict[sim_word] = dists[sim_word_id]\n",
        "    return topN_dict\n",
        "\n",
        "model.eval()\n",
        "for word, sim in get_top_similar(\"excellent\").items():\n",
        "    print(\"{}: {:.3f}\".format(word, sim))\n",
        "\n"
      ],
      "metadata": {
        "id": "b51uwCryuZnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea0a2841-ef75-46f1-e452-67591cf7374e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Japanese: 3.070\n",
            "season: 3.068\n",
            "anywhere: 3.041\n",
            "dishes: 2.797\n",
            "nachos: 2.727\n",
            "basis: 2.715\n",
            "supposed: 2.639\n",
            "restaurant: 2.577\n",
            "affordable: 2.532\n",
            "Yelp: 2.500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZouAmamvTE8W"
      },
      "execution_count": 51,
      "outputs": []
    }
  ]
}